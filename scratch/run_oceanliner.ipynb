{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3e15606-e20b-45ed-872f-1dac2b874aa6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **oceanliner**: observing system simulation experiments (OSSEs) for SWOT in situ campaigns\n",
    "\n",
    "This notebook enables a user to select a region from one of the 15 [Adopt-a-Crossover](https://www.swot-adac.org/) sites and specify a sampling pattern (e.g., the path of an ocean glider, ship-based underway CTD, Wave Glider, Saildrone, or mooring), and then does the following:\n",
    "* download llc4320 data to the local machine\n",
    "* compute steric height and potential vorticity \n",
    "* interpolate model fields in space/time over the trajectory\n",
    "* return set of subsampled variables on a regular grid \n",
    "* store and plot outputs, including \"true\" and \"subsampled\" steric height \n",
    "\n",
    "### User inputs:\n",
    "* **RegionName**: name of region (corresponding to filename) - options are WesternMed  ROAM_MIZ  NewCaledonia  NWPacific  BassStrait  RockallTrough  ACC_SMST MarmaraSea  LabradorSea  CapeBasin Boknis GotlandBasin NWAustralia WestAtlantic Yongala - [link to PO.DAAC data listings](https://podaac.jpl.nasa.gov/datasetlist?ids=Processing+Levels&values=4+-+Gridded+Model+Output&search=Pre-SWOT+llc4320&view=list&provider=)\n",
    "* **start_date**, **ndays**: specify date range as start date & number of days.\n",
    "* **PLATFORM** : simulated platform with with to sample the model: glider track (`glider`), shipboard underway CTD (`uctd`), Wave Glider (`wave_glider`), Saildrone (`saildrone`) mooring (`mooring`), or a user-specified trajectory (`trajectory_file`), in which casea netCDF file **trajectory_file** must also be specified. Specifying a sampling platform applies realistic default values for platform speed and depth range\n",
    "* **PATTERN**: survey PATTERN -- can be `lawnmower` or `back-forth`\n",
    "* **datadir** : directory where data files are stored\n",
    "\n",
    "\n",
    "\n",
    "### Future developments to include:\n",
    "* implement other sampling platforms that interact with model current fields (e.g., drifters)\n",
    "* adapt for the AWS cloud\n",
    "* compute other variables of interest\n",
    "* import simulated SWOT data at the same location\n",
    "* pipe output into optimal interpolation software\n",
    "* implement other models (including biogeochemical model)\n",
    "* efficiency improvements\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b986eb-9b7a-4472-8040-ddbfc81e7290",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "\n",
    "# Native packages\n",
    "from math import radians, degrees, sin, cos, asin, acos, sqrt\n",
    "import datetime\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Third-party packages for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "# Other third-party packages\n",
    "import netCDF4 as nc4\n",
    "\n",
    "# Third-party packages for data interpolation\n",
    "from scipy import interpolate\n",
    "from scipy.interpolate import griddata\n",
    "from xgcm import Grid\n",
    "import xgcm.grid\n",
    "\n",
    "# Third-party packages for data visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from mpl_toolkits import mplot3d\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# osse tools package\n",
    "# del sys.modules['oceanliner_functions']  # uncomment if troubleshooting oceanliner_functions\n",
    "from oceanliner_functions import download_llc4320_data, compute_derived_fields, get_survey_track, survey_interp, rotate_vector_to_EN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b87f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------\n",
    "# USER INPUTS: \n",
    "# --------------------------------------------------------------------\n",
    "# *** users should only have to modify the variables in this cell ***\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# ------------ region and time span\n",
    "\n",
    "# RegionName: region with MITgcm llc4320 data on the PO.DAAC \n",
    "#   options are:\n",
    "#     WesternMed  ROAM_MIZ  NewCaledonia  NWPacific  BassStrait  RockallTrough  ACC_SMST\n",
    "#     MarmaraSea  LabradorSea  CapeBasin Boknis GotlandBasin NWAustralia WestAtlantic Yongala\n",
    "RegionName = 'WesternMed' \n",
    "\n",
    "# start_date:  first date to subsample the model. \n",
    "#   MITgcm llc4320 data are from 2011-Sep-13 to 2012-Nov-15\n",
    "start_date = datetime.date(2012,1,1)\n",
    "# ndays: number of days over which to subsample the model (starting at start_date) \n",
    "#   note: ndays must be >1 \n",
    "#   note: a large number of ndays may crash smaller machines\n",
    "ndays = 5 \n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# ------------ directories -------------------------------------------\n",
    "\n",
    "# directory where data files are stored\n",
    "datadir = '/data3/llc4320/' + RegionName + '/'                     \n",
    "# directory where generated output files will be stored\n",
    "outputdir = '/data3/adac/osse_output/' + RegionName + '/'           \n",
    "# directory where figures will be stored\n",
    "figdir = '/data2/Dropbox/projects/adac/figures/' + RegionName + '/' # store figures\n",
    "# --------------------------------------------------------------------\n",
    "# directory where data files are stored\n",
    "datadir = '/Users/kdrushka/data/adac/mitgcm/netcdf/' + RegionName + '/'                     \n",
    "# directory where generated output files will be stored\n",
    "outputdir = '/data3/adac/osse_output/' + RegionName + '/'           \n",
    "# directory where figures will be stored\n",
    "figdir = '/data2/Dropbox/projects/adac/figures/' + RegionName + '/' # store figures\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ------------ sampling parameters ------------------------------------\n",
    "\n",
    "# PLATFORM: which instrument to sample with:\n",
    "#   options are glider, uctd, mooring, wave_glider, saildrone, waypoints, or trajectory_file\n",
    "PLATFORM = 'glider' \n",
    "# -----  if *only* PLATFORM is specified, reasonable defaults will be selected for the following parameters:\n",
    "\n",
    "# WAYPOINTS:\n",
    "#  specify either a list of lon,lat waypoints as {'x':[151, 153], 'y':[-55, -56]}\n",
    "#    note: for a mooring, specify a single value for x and y\n",
    "#    note: xwaypoints & ywaypoints must have the same size\n",
    "#  or, a filename (string) of a netCDF file specifying the waypoints as {'waypoint_file':'filename.nc'} (EXAMPLE NEEDED)\n",
    "#  or, None - in which case a simple pattern within the domain will be selected based on \"PATTERN\" (useful for testing/demo)\n",
    "#  ** note, if the waypoints are outside of the domain, get_survey_track will raise an error (TODO: add warning earlier)\n",
    "WAYPOINTS = {'x':[3, 3], 'y':[38, 38.2]}\n",
    "\n",
    "# PATTERN: if WAYPOINTS=None, generate waypoints using this pattern:\n",
    "#   options are back-forth (repeated back+forth betwen two waypoints) or lawnmower (radiator survey)\n",
    "#   if waypoints are set, the value of PATTERN is irrelevant \n",
    "PATTERN = 'lawnmower' # back-forth or lawnmower \n",
    "\n",
    "# AT_END: what to do after the end of the list of waypoints is reached.\n",
    "#   options are reverse (follow the track back to the start), repeat (go straight back to start and then repeat) or terminate (stop) \n",
    "AT_END = 'reverse'\n",
    "\n",
    "# zrange: depth range of measurements as a 2-element list. \n",
    "#   * note, if depth values are negative (As in MITgcm), zrange should be negative\n",
    "zrange = [-1, -1000]\n",
    "\n",
    "# z_res: vertical sampling resolution in m\n",
    "z_res = 1\n",
    "\n",
    "# zmooring: for PLATFORM=mooring, \n",
    "#   specify the depth of the instruments\n",
    "#   (default x/y is the center of the domain)\n",
    "zmooring = [-1, -10, -50, -500, -1000]\n",
    "      \n",
    "# hspeed: horizontal speed of the platform (in m/s) \n",
    "hspeed = 0.25\n",
    "\n",
    "# vspeed: vertical speed of the platform through the water (in m/s)\n",
    "#   for glider, this is the speed at which the glider dives\n",
    "#   for uctd, this is the fall-rate of the instrument\n",
    "#   for mooring, wave_glider and saildrone vspeed is irrelevant\n",
    "vspeed = 0.1\n",
    "\n",
    "\n",
    "# DERIVED_VARIABLES: whether or not to compute the \"derived variables\" - 'steric_height', 'N2', and/or 'vorticity'\n",
    "#   it takes significant memory and time to derive and save the stored variables, so None is recommended \n",
    "#   if memory is limited\n",
    "DERIVED_VARIABLES = {'steric_height', 'N2', 'vorticity'} # or, None\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ------------ save flags ------- ------------------------------------\n",
    "\n",
    "# SAVE_FIGURES: if True, save some basic figures\n",
    "SAVE_FIGURES = False \n",
    "\n",
    "# SAVE_PRELIMINARY: if True, save preliminary along-track data. \n",
    "#  This takes more space but is faster and less prone to crashing than the gridding step\n",
    "SAVE_PRELIMINARY = False \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae3644b-3aa8-4f5b-bd13-33ddeb805889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the user-specified details in \"sampling_details\" variable\n",
    "sampling_details = {\n",
    "   'PLATFORM' : PLATFORM,\n",
    "    'WAYPOINTS' : WAYPOINTS,\n",
    "    'PATTERN' : PATTERN,\n",
    "    'zrange' : zrange,  \n",
    "    'z_res' : z_res,\n",
    "    'hspeed' : hspeed,\n",
    "    'vspeed' : vspeed,\n",
    "    'AT_END' : AT_END,\n",
    "    'zmooring' : zmooring,\n",
    "    'DERIVED_VARIABLES' : DERIVED_VARIABLES,\n",
    "    'SAVE_PRELIMINARY' : SAVE_PRELIMINARY,\n",
    "    'start_date' : start_date,\n",
    "    'ndays' : ndays\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8586d15a-b385-407e-8bfe-2288fd6523a3",
   "metadata": {},
   "source": [
    "#### Download & load model data and derived fields\n",
    "\n",
    "Based on [LLC4320](https://data.nas.nasa.gov/viz/vizdata/llc4320/index.html), the 1/48-degree global MITgcm simulation produced by the ECCO project. Ten regional cut-outs of the simulation are available on the [PO.DAAC](https://podaac.jpl.nasa.gov/datasetlist?ids=Processing+Levels&values=4+-+Gridded+Model+Output&search=Pre-SWOT+llc4320&view=list&provider=); the 4x4 degree regional domains are small enough to enable fairly easy downloads and processing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c807660-4015-4593-a01f-0887ac81e4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download files:\n",
    "download_llc4320_data(RegionName, datadir, start_date, ndays)\n",
    "\n",
    "# derive & save new files with steric height & vorticity\n",
    "if sampling_details['DERIVED_VARIABLES']:\n",
    "    compute_derived_fields(RegionName, datadir, start_date, ndays, sampling_details['DERIVED_VARIABLES'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "5904a97a-ab24-4bda-ab0b-2267b6d1b318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_derived_fields_TEST(RegionName, datadir, start_date, ndays, DERIVED_VARIABLES):\n",
    "#     \"\"\" Check for derived files in {datadir}/derived and compute if the files don't exist\n",
    "\n",
    "\n",
    "#     Args:\n",
    "#         RegionName (str): It can be selected from the list of regions with pre-SWOT llc4320 data\n",
    "#         datadir (str): Directory where input model files are stored\n",
    "#         start_date (datetime): Starting date for computing derived fields\n",
    "#         ndays (int): Number of days from the start date to compute derived fields\n",
    "#         DERIVED_VARIABLES (str list): specifies which variables to derive (steric_height, N2 and/or vorticity)\n",
    "\n",
    "#     Returns:\n",
    "#         None\n",
    "        \n",
    "#     Raises: \n",
    "#         TBD: TBD\n",
    "\n",
    "#     \"\"\"\n",
    "from datetime import datetime, date, time, timedelta\n",
    "import gsw as sw\n",
    "# directory to save derived data to - create if doesn't exist\n",
    "derivedir = datadir + 'derived/'\n",
    "if not(os.path.isdir(derivedir)):\n",
    "    os.mkdir(derivedir)\n",
    "\n",
    "# files to load:\n",
    "date_list = [start_date + timedelta(days=x) for x in range(ndays)]\n",
    "target_files = [f'{datadir}LLC4320_pre-SWOT_{RegionName}_{date_list[n].strftime(\"%Y%m%d\")}.nc' for n in range(ndays)] # list target files\n",
    "\n",
    "# list of derived files:\n",
    "derived_files = [f'{derivedir}LLC4320_pre-SWOT_{RegionName}_derived-fields_{date_list[n].strftime(\"%Y%m%d\")}.nc' for n in range(ndays)] # list target files\n",
    "\n",
    "\n",
    "# loop through input files, then do the following:\n",
    "# - compute steric height\n",
    "# - compute N2\n",
    "# - interpolate vector quantities (velocity and wind) to the tracer grid\n",
    "# - compute vorticity\n",
    "fis = range(len(target_files))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "DERIVED_VARIABLES = 'N2'\n",
    "cnt = 0 # count\n",
    "for fi in fis:\n",
    "    # input filename:\n",
    "    thisf=target_files[fi]\n",
    "    # output filename:\n",
    "    fnout = thisf.replace(RegionName + '_' , RegionName + '_derived-fields_')\n",
    "    fnout = fnout.replace(RegionName + '/' , RegionName + '/derived/')\n",
    "    # check if output file already exists\n",
    "    if (not(os.path.isfile(fnout))):   \n",
    "        print(f'computing {DERIVED_VARIABLES} for {thisf}') \n",
    "        # load file:\n",
    "        ds = xr.open_dataset(thisf)\n",
    "\n",
    "        if (('steric_height' in DERIVED_VARIABLES) or ('N2' in DERIVED_VARIABLES)):\n",
    "            # mean lat/lon of domain\n",
    "            xav = ds.XC.isel(j=0).mean(dim='i')\n",
    "            yav = ds.YC.isel(i=0).mean(dim='j')\n",
    "            if 'steric_height' in DERIVED_VARIABLES:\n",
    "                # Steric height calculation requires a reference profile. Get this from Argo.\n",
    "                # -------\n",
    "                # first time through the loop, load reference profile:\n",
    "                # load a single file to get coordinates\n",
    "                if cnt==0:\n",
    "\n",
    "                    # for transforming U and V, and for the vorticity calculation, build the xgcm grid:\n",
    "                    # see https://xgcm.readthedocs.io/en/latest/xgcm-examples/02_mitgcm.html\n",
    "                    grid = xgcm.Grid(ds, coords={'X':{'center': 'i', 'left': 'i_g'}, \n",
    "                                 'Y':{'center': 'j', 'left': 'j_g'},\n",
    "                                 'T':{'center': 'time'},\n",
    "                                 'Z':{'center': 'k'}})\n",
    "\n",
    "\n",
    "                    # --- load reference file of argo data\n",
    "                    # here we use the 3x3 annual mean Argo product on standard produced by IRPC & distributed by ERDDAP\n",
    "                    # https://apdrc.soest.hawaii.edu/erddap/griddap/hawaii_soest_defb_b79c_cb17.html\n",
    "                    # - download the profile closest to xav,yav once (quick), use it, then delete it.\n",
    "\n",
    "                    # URL gets temp & salt at all levels\n",
    "                    argofile = f'https://apdrc.soest.hawaii.edu/erddap/griddap/hawaii_soest_625d_3b64_cc4d.nc?temp[(0000-12-15T00:00:00Z):1:(0000-12-15T00:00:00Z)][(0.0):1:(2000.0)][({yav.data}):1:({yav.data})][({xav.data}):1:({xav.data})],salt[(0000-12-15T00:00:00Z):1:(0000-12-15T00:00:00Z)][(0.0):1:(2000.0)][({yav.data}):1:({yav.data})][({xav.data}):1:({xav.data})]'\n",
    "\n",
    "                    # delete the argo file if it exists \n",
    "                    if os.path.isfile('argo_local.nc'):\n",
    "                        os.remove('argo_local.nc')\n",
    "                    # use requests to get the file, and write locally:\n",
    "                    r = requests.get(argofile)\n",
    "                    file = open('argo_local.nc','wb')\n",
    "                    file.write(r.content)\n",
    "                    file.close()\n",
    "                    # open the argo file:\n",
    "                    argods = xr.open_dataset('argo_local.nc',decode_times=False)\n",
    "                    # get rid of time coord/dim/variable, which screws up the time in ds if it's loaded\n",
    "                    argods = argods.squeeze().reset_coords(names = {'time'}, drop=True) \n",
    "                    # reference profiles: annual average Argo T/S using nearest neighbor\n",
    "                    Tref = argods[\"temp\"]\n",
    "                    Sref = argods[\"salt\"]\n",
    "                    # SA and CT from gsw:\n",
    "                    # see example from https://discourse.pangeo.io/t/wrapped-for-dask-teos-10-gibbs-seawater-gsw-oceanographic-toolbox/466\n",
    "                    Pref = xr.apply_ufunc(sw.p_from_z, -argods.LEV, yav)\n",
    "                    Pref.compute()\n",
    "                    SAref = xr.apply_ufunc(sw.SA_from_SP, Sref, Pref, xav, yav,\n",
    "                                           dask='parallelized', output_dtypes=[Sref.dtype])\n",
    "                    SAref.compute()\n",
    "                    CTref = xr.apply_ufunc(sw.CT_from_pt, Sref, Tref, # Theta is potential temperature\n",
    "                                           dask='parallelized', output_dtypes=[Sref.dtype])\n",
    "                    CTref.compute()\n",
    "                    Dref = xr.apply_ufunc(sw.density.rho, SAref, CTref, Pref,\n",
    "                                        dask='parallelized', output_dtypes=[Sref.dtype])\n",
    "                    Dref.compute()\n",
    "\n",
    "\n",
    "                    cnt = cnt+1\n",
    "                    print()\n",
    "                    # end reference profile calculation\n",
    "\n",
    "\n",
    "            # -------\n",
    "            # --- COMPUTE STERIC HEIGHT and/or N2 IN STEPS ---\n",
    "            # 0. create datasets for variables of interest:\n",
    "            ss = ds.Salt\n",
    "            tt = ds.Theta\n",
    "            pp = xr.DataArray(sw.p_from_z(ds.Z,ds.YC))\n",
    "\n",
    "            # 1. compute absolute salinity and conservative temperature\n",
    "            sa = xr.apply_ufunc(sw.SA_from_SP, ss, pp, xav, yav, dask='parallelized', output_dtypes=[ss.dtype])\n",
    "            sa.compute()\n",
    "            ct = xr.apply_ufunc(sw.CT_from_pt, sa, tt, dask='parallelized', output_dtypes=[ss.dtype])\n",
    "            ct.compute()\n",
    "\n",
    "            # compute N2:\n",
    "            if 'N2' in DERIVED_VARIABLES:\n",
    "                N2, pmid = sw.Nsquared(sa, ct, pp, lat=None, axis=1) # axis 1 = depth\n",
    "                # make into a dataset\n",
    "                N2_ds = N2.to_dataset(name='N2')\n",
    "                print(N2)\n",
    "                print(pmid)\n",
    "                print(N2_ds)\n",
    "\n",
    "\n",
    "            # compute steric height:\n",
    "            if 'steric_height' in DERIVED_VARIABLES:\n",
    "                dd = xr.apply_ufunc(sw.density.rho, sa, ct, pp, dask='parallelized', output_dtypes=[ss.dtype])\n",
    "                dd.compute()\n",
    "                # 2. compute specific volume anomaly: gsw.density.specvol_anom_standard(SA, CT, p)\n",
    "                sva = xr.apply_ufunc(sw.density.specvol_anom_standard, sa, ct, pp, dask='parallelized', output_dtypes=[ss.dtype])\n",
    "                sva.compute()\n",
    "                # 3. compute steric height = integral(0:z1) of Dref(z)*sva(z)*dz(z)\n",
    "                # - first, interpolate Dref to the model pressure levels\n",
    "                Drefi = Dref.interp(LEV=-ds.Z)\n",
    "                dz = -ds.Z_bnds.diff(dim='nb').drop_vars('nb').squeeze() # distance between interfaces\n",
    "\n",
    "                # steric height computation (summation/integral)\n",
    "                # - increase the size of Drefi and dz to match the size of sva\n",
    "                Db = Drefi.broadcast_like(sva)\n",
    "                dzb = dz.broadcast_like(sva)\n",
    "                dum = Db * sva * dzb\n",
    "                sh = dum.cumsum(dim='k') \n",
    "                # this gives sh as a 3-d variable, (where the depth dimension \n",
    "                # represents the deepest level from which the specific volume anomaly was interpolated)\n",
    "                # - but in reality we just want the SH that was determined by integrating over\n",
    "                # the full survey depth, which gives a 2-d output:\n",
    "                sh_true = dum.sum(dim='k') \n",
    "\n",
    "                # make into dataset:\n",
    "                sh_ds = sh.to_dataset(name='steric_height')\n",
    "                sh_true_ds = sh_true.to_dataset(name='steric_height_true')            \n",
    "                # add/rename the Argo reference profile variables to dout:\n",
    "                tref = Tref.to_dataset(name='Tref')\n",
    "                tref = tref.merge(Sref).rename({'salt': 'Sref'}).\\\n",
    "                    rename({'LEV':'zref','latitude':'yav','longitude':'xav'})\n",
    "\n",
    "        if 'vorticity' in DERIVED_VARIABLES:                \n",
    "            # --- COMPUTE VORTICITY using xgcm and interpolate to X, Y\n",
    "            # see https://xgcm.readthedocs.io/en/latest/xgcm-examples/02_mitgcm.html\n",
    "            vorticity = (grid.diff(ds.V*ds.DXG, 'X') - grid.diff(ds.U*ds.DYG, 'Y'))/ds.RAZ\n",
    "            vorticity = grid.interp(grid.interp(vorticity, 'X', boundary='extend'), 'Y', boundary='extend')\n",
    "            # make into dataset\n",
    "            v_ds =vorticity.to_dataset(name='vorticity')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # ------------------\n",
    "        # save derived fields in a new file\n",
    "        if 'steric_height' in DERIVED_VARIABLES:\n",
    "            dout = sh_ds\n",
    "            dout = dout.merge(sh_true_ds)\n",
    "            # - add ref profiles to dout and drop uneeded vars/coords\n",
    "            dout = dout.merge(tref).drop_vars({'longitude','latitude','LEV'})\n",
    "            # - add attributes for all variables\n",
    "            dout.steric_height.attrs = {'long_name' : 'Steric height',\n",
    "                                    'units' : 'm',\n",
    "                                    'comments_1' : 'Computed by integrating the specific volume anomaly (SVA) multiplied by a reference density, where the reference density profile is calculated from temperature & salinity profiles from the APDRC 3x3deg gridded Argo climatology product (accessed through ERDDAP). The profile nearest to the center of the domain is selected, and T & S profiles are averaged over one year before computing ref density. SVA is computed from the model T & S profiles. the Gibbs Seawater Toolbox is used compute reference density and SVA. steric_height is given at all depth levels (dep): steric_height at a given depth represents steric height signal generated by the water column above that depth - so the deepest steric_height value represents total steric height (and is saved in steric_height_true'\n",
    "                                       }\n",
    "            dout.steric_height_true.attrs = dout.steric_height.attrs\n",
    "            dout.Tref.attrs = {'long_name' : f'Reference temperature profile at {yav.data}N,{xav.data}E',\n",
    "                                'units' : 'degree_C',\n",
    "                                'comments_1' : 'From Argo 3x3 climatology produced by APDRC'}\n",
    "            dout.Sref.attrs = {'long_name' : f'Reference salinity profile at {yav.data}N,{xav.data}E',\n",
    "                                    'units' : 'psu',\n",
    "                                    'comments_1' : 'From Argo 3x3 climatology produced by APDRC'}\n",
    "\n",
    "            dout.zref.attrs = {'long_name' : f'Reference depth for Tref and Sref',\n",
    "                                    'units' : 'm',\n",
    "                                    'comments_1' : 'From Argo 3x3 climatology produced by APDRC'}\n",
    "\n",
    "            # merge vorticity \n",
    "            if 'vorticity' in DERIVED_VARIABLES:  \n",
    "                dout = dout.merge(v_ds)\n",
    "\n",
    "        # if we only computed vorticity, dout = v_ds\n",
    "        elif 'vorticity' in DERIVED_VARIABLES:  \n",
    "            dout = v_ds\n",
    "\n",
    "\n",
    "        # if vorticity, add the attrs:\n",
    "        if 'vorticity' in DERIVED_VARIABLES:  \n",
    "            dout.vorticity.attrs = {'long_name' : 'Vertical component of the vorticity',\n",
    "                                'units' : 's-1',\n",
    "                                'comments_1' : 'computed on DXG,DYG then interpolated to X,Y'}         \n",
    "\n",
    "        # - save netcdf file with derived fields\n",
    "        netcdf_fill_value = nc4.default_fillvals['f4']\n",
    "        dv_encoding = {}\n",
    "        for dv in dout.data_vars:\n",
    "            dv_encoding[dv]={'zlib':True,  # turns compression on\\\n",
    "                        'complevel':1,     # 1 = fastest, lowest compression; 9=slowest, highest compression \\\n",
    "                        'shuffle':True,    # shuffle filter can significantly improve compression ratios, and is on by default \\\n",
    "                        'dtype':'float32',\\\n",
    "                        '_FillValue':netcdf_fill_value}\n",
    "        # save to a new file\n",
    "        print(' ... saving to ', fnout)\n",
    "        # TROUBLESHOOTING::::: DELETE THE RETURN LINE\n",
    "        #return dout, dv_encoding\n",
    "        dout.to_netcdf(fnout,format='netcdf4',encoding=dv_encoding)\n",
    "\n",
    "\n",
    "\n",
    "# release Argo file at the end of all files\n",
    "if 'argods' in locals():\n",
    "    argods.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b173c12-bbae-426d-aff6-c6a37179ff6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_details['DERIVED_VARIABLES'] = 'N2'\n",
    "compute_derived_fields_TEST(RegionName, datadir, start_date, ndays, sampling_details['DERIVED_VARIABLES'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "3f1d8a42-1a53-4093-b82b-bf487752f799",
   "metadata": {},
   "outputs": [],
   "source": [
    "N2, pmid = sw.Nsquared(sa, ct, pp, lat=None, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94fd38d-b61d-4831-9bdd-356811cbbd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "N2, pmid = xr.apply_ufunc(sw.Nsquared, sa, ct, pp, kwargs={\"lat\": None, }(lat=None), (axis=1), dask='parallelized', output_dtypes=[ss.dtype])\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "55bd59c1-e60d-44a1-91d3-c44717e41687",
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.apply_ufunc?kwargs={\"axis\": -1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "08a06f96-2049-4f39-8329-de488e3fbb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can't figure out how to make xr.apply_ufunc(sw.Nsquared, sa, ct, pp, kwargs={\"lat\": None, \"axis\":1}, ... ) work, so do it this way\n",
    "N2, pmid = sw.Nsquared(sa, ct, pp, lat=None, axis=1)\n",
    "\n",
    "# interpolate from pmid to depth\n",
    "pmid_av = np.mean(pmid, axis=(0,2,3))\n",
    "zmid = xr.DataArray(sw.z_from_p(pmid_av,np.tile(yav,[len(pmid_av)])))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# N2i = grid.interp(N2, 'X', boundary='extend'), 'Y', boundary='extend')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "5f605974-44e9-44da-a6d7-70dc03c4ba10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperiod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "One-dimensional linear interpolation for monotonically increasing sample points.\n",
       "\n",
       "Returns the one-dimensional piecewise linear interpolant to a function\n",
       "with given discrete data points (`xp`, `fp`), evaluated at `x`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "x : array_like\n",
       "    The x-coordinates at which to evaluate the interpolated values.\n",
       "\n",
       "xp : 1-D sequence of floats\n",
       "    The x-coordinates of the data points, must be increasing if argument\n",
       "    `period` is not specified. Otherwise, `xp` is internally sorted after\n",
       "    normalizing the periodic boundaries with ``xp = xp % period``.\n",
       "\n",
       "fp : 1-D sequence of float or complex\n",
       "    The y-coordinates of the data points, same length as `xp`.\n",
       "\n",
       "left : optional float or complex corresponding to fp\n",
       "    Value to return for `x < xp[0]`, default is `fp[0]`.\n",
       "\n",
       "right : optional float or complex corresponding to fp\n",
       "    Value to return for `x > xp[-1]`, default is `fp[-1]`.\n",
       "\n",
       "period : None or float, optional\n",
       "    A period for the x-coordinates. This parameter allows the proper\n",
       "    interpolation of angular x-coordinates. Parameters `left` and `right`\n",
       "    are ignored if `period` is specified.\n",
       "\n",
       "    .. versionadded:: 1.10.0\n",
       "\n",
       "Returns\n",
       "-------\n",
       "y : float or complex (corresponding to fp) or ndarray\n",
       "    The interpolated values, same shape as `x`.\n",
       "\n",
       "Raises\n",
       "------\n",
       "ValueError\n",
       "    If `xp` and `fp` have different length\n",
       "    If `xp` or `fp` are not 1-D sequences\n",
       "    If `period == 0`\n",
       "\n",
       "See Also\n",
       "--------\n",
       "scipy.interpolate\n",
       "\n",
       "Warnings\n",
       "--------\n",
       "The x-coordinate sequence is expected to be increasing, but this is not\n",
       "explicitly enforced.  However, if the sequence `xp` is non-increasing,\n",
       "interpolation results are meaningless.\n",
       "\n",
       "Note that, since NaN is unsortable, `xp` also cannot contain NaNs.\n",
       "\n",
       "A simple check for `xp` being strictly increasing is::\n",
       "\n",
       "    np.all(np.diff(xp) > 0)\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> xp = [1, 2, 3]\n",
       ">>> fp = [3, 2, 0]\n",
       ">>> np.interp(2.5, xp, fp)\n",
       "1.0\n",
       ">>> np.interp([0, 1, 1.5, 2.72, 3.14], xp, fp)\n",
       "array([3.  , 3.  , 2.5 , 0.56, 0.  ])\n",
       ">>> UNDEF = -99.0\n",
       ">>> np.interp(3.14, xp, fp, right=UNDEF)\n",
       "-99.0\n",
       "\n",
       "Plot an interpolant to the sine function:\n",
       "\n",
       ">>> x = np.linspace(0, 2*np.pi, 10)\n",
       ">>> y = np.sin(x)\n",
       ">>> xvals = np.linspace(0, 2*np.pi, 50)\n",
       ">>> yinterp = np.interp(xvals, x, y)\n",
       ">>> import matplotlib.pyplot as plt\n",
       ">>> plt.plot(x, y, 'o')\n",
       "[<matplotlib.lines.Line2D object at 0x...>]\n",
       ">>> plt.plot(xvals, yinterp, '-x')\n",
       "[<matplotlib.lines.Line2D object at 0x...>]\n",
       ">>> plt.show()\n",
       "\n",
       "Interpolation with periodic x-coordinates:\n",
       "\n",
       ">>> x = [-180, -170, -185, 185, -10, -5, 0, 365]\n",
       ">>> xp = [190, -190, 350, -350]\n",
       ">>> fp = [5, 10, 3, 4]\n",
       ">>> np.interp(x, xp, fp, period=360)\n",
       "array([7.5 , 5.  , 8.75, 6.25, 3.  , 3.25, 3.5 , 3.75])\n",
       "\n",
       "Complex interpolation:\n",
       "\n",
       ">>> x = [1.5, 4.0]\n",
       ">>> xp = [2,3,5]\n",
       ">>> fp = [1.0j, 0, 2+3j]\n",
       ">>> np.interp(x, xp, fp)\n",
       "array([0.+1.j , 1.+1.5j])\n",
       "\u001b[0;31mFile:\u001b[0m      ~/opt/miniconda3/envs/py33/lib/python3.9/site-packages/numpy/lib/function_base.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# interpolate N2 to the vertical depth grid from zmid\n",
    "# N2i = np.interp\n",
    "np.interp?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "6db7acc5-40cf-4044-90c8-f91f5581e11f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "different number of dimensions on data and dims: 1 vs 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/dn/z4fyhv0d6xggfhfqbl6b4cwm0000gq/T/ipykernel_8179/2716739279.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# make into dataarrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mN2_da\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'k'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'j'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mzmid_da\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzmid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'k'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'j'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/miniconda3/envs/py33/lib/python3.9/site-packages/xarray/core/dataarray.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, coords, dims, name, attrs, indexes, fastpath)\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                     \u001b[0mcoords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m                 \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndexVariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m                     \u001b[0mcoords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/py33/lib/python3.9/site-packages/xarray/core/dataarray.py\u001b[0m in \u001b[0;36m_infer_coords_and_dims\u001b[0;34m(shape, coords, dims)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mdims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34mf\"dim_{n}\"\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcoords\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;31m# try to infer dimensions from coords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dict_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0mdims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: different number of dimensions on data and dims: 1 vs 4"
     ]
    }
   ],
   "source": [
    "# make into dataarrays\n",
    "N2_da = xr.DataArray(N2, dims=['time', 'k', 'j','i'])\n",
    "zmid_da = xr.DataArray(zmid, dims=['time', 'k', 'j','i'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "92a6ce7a-b278-4352-a725-0c1773887a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2 {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.DataArray (time: 24, k: 76, j: 265, i: 192)&gt;\n",
       "array([[[[36.93358417, 36.93617145, 36.93583032, ...,         nan,\n",
       "                  nan,         nan],\n",
       "         [36.94230427, 36.93964033, 36.93811862, ...,         nan,\n",
       "                  nan,         nan],\n",
       "         [36.94573864, 36.9443051 , 36.94172165, ...,         nan,\n",
       "                  nan,         nan],\n",
       "         ...,\n",
       "         [37.76482178, 37.76510542, 37.76504409, ..., 37.80990562,\n",
       "          37.81847239, 37.83372009],\n",
       "         [37.76487161, 37.76536606, 37.76521658, ..., 37.87431548,\n",
       "          37.87476394, 37.86966221],\n",
       "         [37.76551938, 37.76396318, 37.76417783, ..., 37.88760835,\n",
       "          37.86945523, 37.86759622]],\n",
       "\n",
       "        [[36.93344034, 36.93609279, 36.93567499, ...,         nan,\n",
       "                  nan,         nan],\n",
       "         [36.94210295, 36.93949267, 36.93795946, ...,         nan,\n",
       "                  nan,         nan],\n",
       "         [36.94553349, 36.94411528, 36.94153566, ...,         nan,\n",
       "                  nan,         nan],\n",
       "...\n",
       "         [        nan,         nan,         nan, ..., 38.61060888,\n",
       "          38.6109385 , 38.61096917],\n",
       "         [        nan,         nan,         nan, ..., 38.61089634,\n",
       "          38.61057822, 38.61007995],\n",
       "         [        nan,         nan,         nan, ..., 38.61019877,\n",
       "          38.60973883, 38.60958551]],\n",
       "\n",
       "        [[        nan,         nan,         nan, ...,         nan,\n",
       "                  nan,         nan],\n",
       "         [        nan,         nan,         nan, ...,         nan,\n",
       "                  nan,         nan],\n",
       "         [        nan,         nan,         nan, ...,         nan,\n",
       "                  nan,         nan],\n",
       "         ...,\n",
       "         [        nan,         nan,         nan, ...,         nan,\n",
       "                  nan,         nan],\n",
       "         [        nan,         nan,         nan, ...,         nan,\n",
       "                  nan,         nan],\n",
       "         [        nan,         nan,         nan, ...,         nan,\n",
       "                  nan,         nan]]]])\n",
       "Coordinates:\n",
       "  * i        (i) float32 0.0 1.0 2.0 3.0 4.0 ... 187.0 188.0 189.0 190.0 191.0\n",
       "  * j        (j) float32 0.0 1.0 2.0 3.0 4.0 ... 260.0 261.0 262.0 263.0 264.0\n",
       "  * k        (k) int32 0 1 2 3 4 5 6 7 8 9 10 ... 66 67 68 69 70 71 72 73 74 75\n",
       "  * time     (time) datetime64[ns] 2012-01-05 ... 2012-01-05T23:00:00</pre><div class='xr-wrap' hidden><div class='xr-header'><div class='xr-obj-type'>xarray.DataArray</div><div class='xr-array-name'></div><ul class='xr-dim-list'><li><span class='xr-has-index'>time</span>: 24</li><li><span class='xr-has-index'>k</span>: 76</li><li><span class='xr-has-index'>j</span>: 265</li><li><span class='xr-has-index'>i</span>: 192</li></ul></div><ul class='xr-sections'><li class='xr-section-item'><div class='xr-array-wrap'><input id='section-7ca24ed0-0187-4fda-875b-fca53c56c30f' class='xr-array-in' type='checkbox' checked><label for='section-7ca24ed0-0187-4fda-875b-fca53c56c30f' title='Show/hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-array-preview xr-preview'><span>36.93 36.94 36.94 36.93 nan nan nan ... nan nan nan nan nan nan nan</span></div><div class='xr-array-data'><pre>array([[[[36.93358417, 36.93617145, 36.93583032, ...,         nan,\n",
       "                  nan,         nan],\n",
       "         [36.94230427, 36.93964033, 36.93811862, ...,         nan,\n",
       "                  nan,         nan],\n",
       "         [36.94573864, 36.9443051 , 36.94172165, ...,         nan,\n",
       "                  nan,         nan],\n",
       "         ...,\n",
       "         [37.76482178, 37.76510542, 37.76504409, ..., 37.80990562,\n",
       "          37.81847239, 37.83372009],\n",
       "         [37.76487161, 37.76536606, 37.76521658, ..., 37.87431548,\n",
       "          37.87476394, 37.86966221],\n",
       "         [37.76551938, 37.76396318, 37.76417783, ..., 37.88760835,\n",
       "          37.86945523, 37.86759622]],\n",
       "\n",
       "        [[36.93344034, 36.93609279, 36.93567499, ...,         nan,\n",
       "                  nan,         nan],\n",
       "         [36.94210295, 36.93949267, 36.93795946, ...,         nan,\n",
       "                  nan,         nan],\n",
       "         [36.94553349, 36.94411528, 36.94153566, ...,         nan,\n",
       "                  nan,         nan],\n",
       "...\n",
       "         [        nan,         nan,         nan, ..., 38.61060888,\n",
       "          38.6109385 , 38.61096917],\n",
       "         [        nan,         nan,         nan, ..., 38.61089634,\n",
       "          38.61057822, 38.61007995],\n",
       "         [        nan,         nan,         nan, ..., 38.61019877,\n",
       "          38.60973883, 38.60958551]],\n",
       "\n",
       "        [[        nan,         nan,         nan, ...,         nan,\n",
       "                  nan,         nan],\n",
       "         [        nan,         nan,         nan, ...,         nan,\n",
       "                  nan,         nan],\n",
       "         [        nan,         nan,         nan, ...,         nan,\n",
       "                  nan,         nan],\n",
       "         ...,\n",
       "         [        nan,         nan,         nan, ...,         nan,\n",
       "                  nan,         nan],\n",
       "         [        nan,         nan,         nan, ...,         nan,\n",
       "                  nan,         nan],\n",
       "         [        nan,         nan,         nan, ...,         nan,\n",
       "                  nan,         nan]]]])</pre></div></div></li><li class='xr-section-item'><input id='section-fda8986b-ac7f-4138-9766-bb1971841f2d' class='xr-section-summary-in' type='checkbox'  checked><label for='section-fda8986b-ac7f-4138-9766-bb1971841f2d' class='xr-section-summary' >Coordinates: <span>(4)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>i</span></div><div class='xr-var-dims'>(i)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>0.0 1.0 2.0 ... 189.0 190.0 191.0</div><input id='attrs-250735fc-2e48-4c42-a5e9-aa587eb4f9a1' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-250735fc-2e48-4c42-a5e9-aa587eb4f9a1' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-fd34559b-0721-43e5-b7c6-0f5537d8f326' class='xr-var-data-in' type='checkbox'><label for='data-fd34559b-0721-43e5-b7c6-0f5537d8f326' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,  11.,\n",
       "        12.,  13.,  14.,  15.,  16.,  17.,  18.,  19.,  20.,  21.,  22.,  23.,\n",
       "        24.,  25.,  26.,  27.,  28.,  29.,  30.,  31.,  32.,  33.,  34.,  35.,\n",
       "        36.,  37.,  38.,  39.,  40.,  41.,  42.,  43.,  44.,  45.,  46.,  47.,\n",
       "        48.,  49.,  50.,  51.,  52.,  53.,  54.,  55.,  56.,  57.,  58.,  59.,\n",
       "        60.,  61.,  62.,  63.,  64.,  65.,  66.,  67.,  68.,  69.,  70.,  71.,\n",
       "        72.,  73.,  74.,  75.,  76.,  77.,  78.,  79.,  80.,  81.,  82.,  83.,\n",
       "        84.,  85.,  86.,  87.,  88.,  89.,  90.,  91.,  92.,  93.,  94.,  95.,\n",
       "        96.,  97.,  98.,  99., 100., 101., 102., 103., 104., 105., 106., 107.,\n",
       "       108., 109., 110., 111., 112., 113., 114., 115., 116., 117., 118., 119.,\n",
       "       120., 121., 122., 123., 124., 125., 126., 127., 128., 129., 130., 131.,\n",
       "       132., 133., 134., 135., 136., 137., 138., 139., 140., 141., 142., 143.,\n",
       "       144., 145., 146., 147., 148., 149., 150., 151., 152., 153., 154., 155.,\n",
       "       156., 157., 158., 159., 160., 161., 162., 163., 164., 165., 166., 167.,\n",
       "       168., 169., 170., 171., 172., 173., 174., 175., 176., 177., 178., 179.,\n",
       "       180., 181., 182., 183., 184., 185., 186., 187., 188., 189., 190., 191.],\n",
       "      dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>j</span></div><div class='xr-var-dims'>(j)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>0.0 1.0 2.0 ... 262.0 263.0 264.0</div><input id='attrs-06b2764d-a646-4aa1-aab3-c9fb3cd347b5' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-06b2764d-a646-4aa1-aab3-c9fb3cd347b5' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-13d239d2-a87c-48e4-b06a-57c3670efcf5' class='xr-var-data-in' type='checkbox'><label for='data-13d239d2-a87c-48e4-b06a-57c3670efcf5' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([  0.,   1.,   2., ..., 262., 263., 264.], dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>k</span></div><div class='xr-var-dims'>(k)</div><div class='xr-var-dtype'>int32</div><div class='xr-var-preview xr-preview'>0 1 2 3 4 5 6 ... 70 71 72 73 74 75</div><input id='attrs-915c1a1c-a083-46b2-96fe-eff4f0e6622c' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-915c1a1c-a083-46b2-96fe-eff4f0e6622c' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-e3aa19e4-1896-43bc-831f-d78a0e5dfd68' class='xr-var-data-in' type='checkbox'><label for='data-e3aa19e4-1896-43bc-831f-d78a0e5dfd68' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
       "       54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
       "       72, 73, 74, 75], dtype=int32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>2012-01-05 ... 2012-01-05T23:00:00</div><input id='attrs-f358ccdf-8573-4cdf-a897-990685870857' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-f358ccdf-8573-4cdf-a897-990685870857' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-a817dc0b-7bd5-45de-8c06-a2563b72539d' class='xr-var-data-in' type='checkbox'><label for='data-a817dc0b-7bd5-45de-8c06-a2563b72539d' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;2012-01-05T00:00:00.000000000&#x27;, &#x27;2012-01-05T01:00:00.000000000&#x27;,\n",
       "       &#x27;2012-01-05T02:00:00.000000000&#x27;, &#x27;2012-01-05T03:00:00.000000000&#x27;,\n",
       "       &#x27;2012-01-05T04:00:00.000000000&#x27;, &#x27;2012-01-05T05:00:00.000000000&#x27;,\n",
       "       &#x27;2012-01-05T06:00:00.000000000&#x27;, &#x27;2012-01-05T07:00:00.000000000&#x27;,\n",
       "       &#x27;2012-01-05T08:00:00.000000000&#x27;, &#x27;2012-01-05T09:00:00.000000000&#x27;,\n",
       "       &#x27;2012-01-05T10:00:00.000000000&#x27;, &#x27;2012-01-05T11:00:00.000000000&#x27;,\n",
       "       &#x27;2012-01-05T12:00:00.000000000&#x27;, &#x27;2012-01-05T13:00:00.000000000&#x27;,\n",
       "       &#x27;2012-01-05T14:00:00.000000000&#x27;, &#x27;2012-01-05T15:00:00.000000000&#x27;,\n",
       "       &#x27;2012-01-05T16:00:00.000000000&#x27;, &#x27;2012-01-05T17:00:00.000000000&#x27;,\n",
       "       &#x27;2012-01-05T18:00:00.000000000&#x27;, &#x27;2012-01-05T19:00:00.000000000&#x27;,\n",
       "       &#x27;2012-01-05T20:00:00.000000000&#x27;, &#x27;2012-01-05T21:00:00.000000000&#x27;,\n",
       "       &#x27;2012-01-05T22:00:00.000000000&#x27;, &#x27;2012-01-05T23:00:00.000000000&#x27;],\n",
       "      dtype=&#x27;datetime64[ns]&#x27;)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-c5275c38-d04a-4bb9-8fe7-3d4cbf0d5869' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-c5275c38-d04a-4bb9-8fe7-3d4cbf0d5869' class='xr-section-summary'  title='Expand/collapse section'>Attributes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.DataArray (time: 24, k: 76, j: 265, i: 192)>\n",
       "array([[[[36.93358417, 36.93617145, 36.93583032, ...,         nan,\n",
       "                  nan,         nan],\n",
       "         [36.94230427, 36.93964033, 36.93811862, ...,         nan,\n",
       "                  nan,         nan],\n",
       "         [36.94573864, 36.9443051 , 36.94172165, ...,         nan,\n",
       "                  nan,         nan],\n",
       "         ...,\n",
       "         [37.76482178, 37.76510542, 37.76504409, ..., 37.80990562,\n",
       "          37.81847239, 37.83372009],\n",
       "         [37.76487161, 37.76536606, 37.76521658, ..., 37.87431548,\n",
       "          37.87476394, 37.86966221],\n",
       "         [37.76551938, 37.76396318, 37.76417783, ..., 37.88760835,\n",
       "          37.86945523, 37.86759622]],\n",
       "\n",
       "        [[36.93344034, 36.93609279, 36.93567499, ...,         nan,\n",
       "                  nan,         nan],\n",
       "         [36.94210295, 36.93949267, 36.93795946, ...,         nan,\n",
       "                  nan,         nan],\n",
       "         [36.94553349, 36.94411528, 36.94153566, ...,         nan,\n",
       "                  nan,         nan],\n",
       "...\n",
       "         [        nan,         nan,         nan, ..., 38.61060888,\n",
       "          38.6109385 , 38.61096917],\n",
       "         [        nan,         nan,         nan, ..., 38.61089634,\n",
       "          38.61057822, 38.61007995],\n",
       "         [        nan,         nan,         nan, ..., 38.61019877,\n",
       "          38.60973883, 38.60958551]],\n",
       "\n",
       "        [[        nan,         nan,         nan, ...,         nan,\n",
       "                  nan,         nan],\n",
       "         [        nan,         nan,         nan, ...,         nan,\n",
       "                  nan,         nan],\n",
       "         [        nan,         nan,         nan, ...,         nan,\n",
       "                  nan,         nan],\n",
       "         ...,\n",
       "         [        nan,         nan,         nan, ...,         nan,\n",
       "                  nan,         nan],\n",
       "         [        nan,         nan,         nan, ...,         nan,\n",
       "                  nan,         nan],\n",
       "         [        nan,         nan,         nan, ...,         nan,\n",
       "                  nan,         nan]]]])\n",
       "Coordinates:\n",
       "  * i        (i) float32 0.0 1.0 2.0 3.0 4.0 ... 187.0 188.0 189.0 190.0 191.0\n",
       "  * j        (j) float32 0.0 1.0 2.0 3.0 4.0 ... 260.0 261.0 262.0 263.0 264.0\n",
       "  * k        (k) int32 0 1 2 3 4 5 6 7 8 9 10 ... 66 67 68 69 70 71 72 73 74 75\n",
       "  * time     (time) datetime64[ns] 2012-01-05 ... 2012-01-05T23:00:00"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# N2\n",
    "\n",
    "# xarray.DataArray(data=<NA>, coords=None, dims=None, name=None, attrs=None, indexes=None, fastpath=False)\n",
    "sa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205aae80-6491-4164-b062-9d7c4489452a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e25a50-d81a-49a0-bd98-54e722a68c6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a8a222-d275-4af4-837f-fa443b3ba4b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e97d9e34-5d72-49fa-9f1a-3c5e1a14fb03",
   "metadata": {},
   "source": [
    "#### Load all model data files. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88ea632-e4e8-4ed6-a283-263fb2e05de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "date_list = [start_date + datetime.timedelta(days=x) for x in range(ndays)]\n",
    "target_files = [f'{datadir}LLC4320_pre-SWOT_{RegionName}_{date_list[n].strftime(\"%Y%m%d\")}.nc' for n in range(ndays)] # list target files\n",
    "\n",
    "# open the dataset\n",
    "ds = xr.open_mfdataset(target_files)\n",
    "\n",
    "# XC, YC and Z are the same at all times, so select a single time\n",
    "# (note, this breaks for a single file - always load >1 file)\n",
    "X = ds.XC.isel(time=0) \n",
    "Y = ds.YC.isel(time=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3b3b2b-34ad-4402-b762-86fd2a1c0693",
   "metadata": {},
   "source": [
    "### Transform vector quantities to the tracer grid and rotate if needed\n",
    "\n",
    "At higher latitudes, vector quantities (U/V/TAU_U/TAU_V) are in model coordinates and must be rotated to earth coordinates\n",
    "rotation vectors are given in AngleSN, AngleCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16f665c-514b-4b84-8a78-774383f4c432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, interpolate U,V and oceTAUX, oceTAUY to the tracer grid\n",
    "print('interpolating to tracer grid')\n",
    "\n",
    "# xgcm.Grid interp raises a DeprecationWarning\n",
    "warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n",
    "\n",
    "\n",
    "# define grid\n",
    "grid = xgcm.Grid(ds, coords={'X':{'center': 'i', 'left': 'i_g'}, \n",
    "                     'Y':{'center': 'j', 'left': 'j_g'},\n",
    "                     'T':{'center': 'time'},\n",
    "                     'Z':{'center': 'k'}})    \n",
    "U_c = grid.interp(ds.U, 'X', boundary='extend')\n",
    "V_c = grid.interp(ds.V, 'Y', boundary='extend')\n",
    "# do the same for TAUX and TAUY:\n",
    "oceTAUX_c = grid.interp(ds.oceTAUX, 'X', boundary='extend')\n",
    "oceTAUY_c = grid.interp(ds.oceTAUY, 'Y', boundary='extend')\n",
    "\n",
    "\n",
    "# second, rotate vectors to geophysical (east, north) coordinates instead of model ones \n",
    "# (if needed, i.e. if AngleSN exists)\n",
    "angles = \"AngleSN\"\n",
    "if 'AngleSN' in list(ds.data_vars):\n",
    "    print('Rotating vector quantities to east/north')\n",
    "    U_c, V_c = rotate_vector_to_EN(U_c, V_c, ds['AngleCS'], ds['AngleSN'])\n",
    "    oceTAUX_c, oceTAUY_c = rotate_vector_to_EN(oceTAUX_c, oceTAUY_c, ds['AngleCS'], ds['AngleSN'])\n",
    "\n",
    "# replace the vector variables in ds \n",
    "print('replacing vectors with tracer-grid versions')\n",
    "ds['U'] = U_c\n",
    "ds['V'] = V_c\n",
    "ds['oceTAUX'] = oceTAUX_c\n",
    "ds['oceTAUY'] = oceTAUY_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a6474f-98fa-43c6-8f4d-aca9820518fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# load the corresponding derived fields \n",
    "if sampling_details['DERIVED_VARIABLES']:\n",
    "    derivedir = datadir + 'derived/'\n",
    "    derived_files = [f'{derivedir}LLC4320_pre-SWOT_{RegionName}_derived-fields_{date_list[n].strftime(\"%Y%m%d\")}.nc' for n in range(ndays)] # list target files\n",
    "    dsd = xr.open_mfdataset(derived_files)\n",
    "    \n",
    "    # merge the derived and raw data\n",
    "    ds = ds.merge(dsd)\n",
    "    \n",
    "# drop a bunch of other vars we don't actually use - can comment this out if these are wanted\n",
    "ds = ds.drop_vars({'DXV','DYU', 'DXC','DXG', 'DYC','DYG', 'XC_bnds', 'YC_bnds', 'Zp1', 'Zu','Zl','Z_bnds', 'nb'})\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83d3397-c4bf-430d-bf07-4dae3a064cc5",
   "metadata": {},
   "source": [
    "### Create & plot sampling track\n",
    "\n",
    "Use the `get_survey_track` function to apply the sampling strategy specified in `sampling_details`\n",
    "\n",
    "returns:\n",
    "* `survey_track`: lat/lon/time/depth of the platform's track,\n",
    "* `survey_indices`: indices of the survey track in \"ds\"\n",
    "* `sampling_details`: the actual sampling details used, ie, those that were specified + any default values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9f0f6d-6f28-46a1-84fb-edc3aeda271b",
   "metadata": {},
   "outputs": [],
   "source": [
    "del sys.modules['oceanliner_functions']  # uncomment if troubleshooting oceanliner_functions\n",
    "from oceanliner_functions import download_llc4320_data, compute_derived_fields, get_survey_track, survey_interp\n",
    "\n",
    "survey_track, survey_indices, sampling_details = get_survey_track(ds, sampling_details)\n",
    "\n",
    "# print:\n",
    "sampling_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f025da37-ec9d-4955-b4d1-5cd716c1800c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- generate name of file to save outputs in ---- \n",
    "filename_base = (f'OSSE_{RegionName}_{sampling_details[\"PLATFORM\"]}_{start_date}_to_{start_date + datetime.timedelta(ndays)}_maxdepth{int(sampling_details[\"zrange\"][1])}')\n",
    "filename_out_base = (f'{outputdir}{filename_base}')\n",
    "print(filename_base)\n",
    "sampling_details['filename_out_base'] = filename_out_base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ce76d0-e954-4d3f-a3ea-34a752b57686",
   "metadata": {},
   "source": [
    "### Visualize the sampling track over a single model snapshot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6585a353-c3a7-465d-ae97-b1bdf859a7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(20,5))\n",
    "\n",
    "# map of Theta at time zero\n",
    "ax = plt.subplot(1,3,1)\n",
    "ssto = plt.pcolormesh(X,Y,ds.Theta.isel(k=0, time=0).values, shading='auto')\n",
    "if not (sampling_details['PLATFORM'] == 'mooring' or sampling_details['PLATFORM'] == 'sim_mooring'):\n",
    "    tracko = plt.scatter(survey_track.lon, survey_track.lat, c=(survey_track.time-survey_track.time[0])/1e9/86400, cmap='Reds', s=0.75)\n",
    "    plt.colorbar(ssto).set_label('SST, $^o$C')\n",
    "    plt.colorbar(tracko).set_label('days from start')\n",
    "    plt.title('SST and survey track: ' + RegionName)\n",
    "else:\n",
    "    plt.plot(survey_track.lon, survey_track.lat, marker='*', c='r')\n",
    "    plt.title('SST and mooring location: ' + RegionName + ' region')\n",
    "\n",
    "\n",
    "# depth/time plot of first few datapoints\n",
    "ax = plt.subplot(1,3,2)\n",
    "iplot = slice(0,20000)\n",
    "if not (sampling_details['PLATFORM'] == 'mooring'):\n",
    "    plt.plot(survey_track.time.isel(points=iplot), survey_track.dep.isel(points=iplot), marker='.')\n",
    "else:\n",
    "    # not quite right but good enough for now.\n",
    "    # (times shouldn't increase with depth)\n",
    "    plt.scatter((np.tile(survey_track['time'].isel(time=iplot), int(survey_track['dep'].data.size))),\n",
    "         np.tile(survey_track['dep'], int(survey_track['time'].isel(time=iplot).data.size)),marker='.')             \n",
    "# plt.xlim([start_date + datetime.timedelta(days=0), start_date + datetime.timedelta(days=2)])\n",
    "plt.ylabel('Depth, m')\n",
    "plt.gca().xaxis.set_major_locator(mdates.DayLocator(interval=1))\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.title('Sampling pattern')\n",
    "\n",
    "# lon/time plot\n",
    "ax = plt.subplot(1,3,3)\n",
    "iplot = slice(0,20000)\n",
    "if not (sampling_details['PLATFORM'] == 'mooring'):\n",
    "    plt.plot(survey_track.time.isel(points=iplot), survey_track.lon.isel(points=iplot), marker='.')\n",
    "else:\n",
    "    # not quite right but good enough for now.\n",
    "    # (times shouldn't increase with depth)\n",
    "    plt.scatter((np.tile(survey_track['time'].isel(time=iplot), int(survey_track['lon'].data.size))),\n",
    "         np.tile(survey_track['lon'], int(survey_track['time'].isel(time=iplot).data.size)),marker='.')             \n",
    "# plt.xlim([start_date + datetime.timedelta(days=0), start_date + datetime.timedelta(days=2)])\n",
    "plt.ylabel('Lon')\n",
    "plt.gca().xaxis.set_major_locator(mdates.DayLocator(interval=1))\n",
    "plt.gcf().autofmt_xdate()\n",
    "\n",
    "\n",
    "\n",
    "# save\n",
    "if SAVE_FIGURES:\n",
    "    plt.savefig(figdir + filename_base + '_sampling.png', dpi=400, transparent=False, facecolor='white')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0e11cc-a32d-4020-8d60-2c46f93c763e",
   "metadata": {},
   "source": [
    "### MAIN FUNCTION OF OCEANLINER:\n",
    "Interpolate data with the specified sampling PATTERN to create `subsampled_data` then put on a regular grid and store in `sgridded`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d93276e-31e5-472b-85b0-f790f11ed274",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# xarray raises a future version / depracation warning...\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning)\n",
    "\n",
    "subsampled_data, sgridded = survey_interp(ds, survey_track, survey_indices, sampling_details)\n",
    "sgridded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2b399b-07b5-47f3-afd8-27571acd9c8a",
   "metadata": {},
   "source": [
    "### Visualizations\n",
    "\n",
    "Basic plots to show the interpolated variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7267d1f-aa2d-4fdc-b1d7-16f26545d167",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# - base list of vbls:\n",
    "vbls3d = ['Theta','Salt', 'U', 'V']\n",
    "# if derived fields, add those to the list:\n",
    "if sampling_details['DERIVED_VARIABLES']:\n",
    "    if ('steric_height' in sampling_details['DERIVED_VARIABLES']):\n",
    "        vbls3d.append('steric_height')\n",
    "    if ('vorticity' in sampling_details['DERIVED_VARIABLES']):\n",
    "        vbls3d.append('vorticity')\n",
    "\n",
    "ylim = [min(sgridded['depth'].values), max(sgridded['depth'].values)]\n",
    "# ylim = [-200, -1]\n",
    "\n",
    "nr = len(vbls3d) # # of rows\n",
    "fig,ax=plt.subplots(nr,figsize=(8,len(vbls3d)*2),constrained_layout=True)\n",
    "\n",
    "\n",
    "for j in range(nr):\n",
    "    sgridded[vbls3d[j]].plot(ax=ax[j], ylim=ylim)\n",
    "    ax[j].plot(sgridded.time.data, -sgridded.KPPhbl.data, c='k')\n",
    "    ax[j].set_title(vbls3d[j])\n",
    "\n",
    "if SAVE_FIGURES:\n",
    "    plt.savefig(figdir + filename_base + '_3D.png', dpi=400, transparent=False, facecolor='white')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45170e53-31c4-4e48-904e-5f996d8185d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## selected 2d fields\n",
    "j=0\n",
    "nr = 6 # # of rows\n",
    "fig,ax=plt.subplots(nr,figsize=(10,8),constrained_layout=True)\n",
    "\n",
    "\n",
    "# wind vectors\n",
    "ax[j].quiver(sgridded.time.data,0,sgridded.oceTAUX.data, sgridded.oceTAUY.data)\n",
    "ax[j].set_title('Wind stress')    \n",
    "ax[j].set_ylabel('N m-2')\n",
    "# SH \n",
    "if sampling_details['DERIVED_VARIABLES']:\n",
    "    if ('steric_height' in sampling_details['DERIVED_VARIABLES']):\n",
    "        j+=1\n",
    "        ax[j].plot(sgridded.time,sgridded.steric_height-sgridded.steric_height.mean(), \n",
    "                     sgridded.time.data,sgridded.steric_height_true-sgridded.steric_height_true.mean())\n",
    "        ax[j].set_title('Steric height')\n",
    "        ax[j].legend(['subsampled','true'])\n",
    "        ax[j].set_ylabel('m')\n",
    "\n",
    "# SSH\n",
    "j+=1\n",
    "ax[j].plot(sgridded.time,sgridded.Eta)\n",
    "ax[j].set_title('SSH')\n",
    "ax[j].set_ylabel('m')\n",
    "\n",
    "# MLD\n",
    "j+=1\n",
    "ax[j].plot(sgridded.time,sgridded.KPPhbl)\n",
    "ax[j].set_title('MLD')\n",
    "ax[j].set_ylabel('m')\n",
    "ax[j].invert_yaxis()\n",
    "\n",
    "# surface heat flux\n",
    "j+=1\n",
    "ax[j].plot(sgridded.time,sgridded.oceQnet, sgridded.time,sgridded.oceQsw)\n",
    "ax[j].set_title('Surface heat flux into the ocean')\n",
    "ax[j].legend(['total','shortwave'])\n",
    "ax[j].set_ylabel('W m-2')\n",
    "\n",
    "# surface FW flux\n",
    "j+=1\n",
    "ax[j].plot(sgridded.time,sgridded.oceFWflx)\n",
    "ax[j].set_title('Surface freshwater flux into the ocean') \n",
    "ax[j].set_ylabel('kg m-2 s-1')\n",
    "\n",
    "# horiz line:\n",
    "for j in range(nr):\n",
    "    ax[j].axhline(0, color='grey', linewidth=0.8)\n",
    "\n",
    "if SAVE_FIGURES:\n",
    "    plt.savefig(figdir + filename_base + '_2D.png', dpi=400, transparent=False, facecolor='white')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b51cde-5136-4f2d-9ef9-511e5c65eb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.steric_height.isel(k=-1, j=100, i=100).plot(x='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116ef800-bd86-4efb-9808-26bfe4473058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sgridded, steric height looks v different from total... why???\n",
    "\n",
    "# check: does ds.sh_true looks like ds.sh? YES\n",
    "plt.plot(ds.steric_height_true.isel(j=100, i=100).data - np.mean(ds.steric_height_true.isel(j=100, i=100).data))\n",
    "plt.plot(ds.steric_height.isel(j=100, i=100, k=51).data - np.mean(ds.steric_height.isel(j=100, i=100, k=51).data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8710c60b-fdbe-449e-94ea-dd3f57e39b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check: does subsanpled sh look right? NO it seems to be rotated???\n",
    "plt.scatter(subsampled_data.time.data, subsampled_data.dep.data, c=subsampled_data.steric_height_true.data)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2699f4d5-58c4-4306-89b8-ed1bfa917565",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(subsampled_data.time.data, subsampled_data.dep.data, c=subsampled_data.steric_height.data)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8898cf86-3db5-434c-bdbc-126e429445d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c3cf95-69c9-49ce-8cc9-e40d74b38a38",
   "metadata": {},
   "source": [
    "### Save interpolated data\n",
    "\n",
    "Fvaluesth raw and gridded subsampled data, add attributes and save\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90a72a8-4d21-49be-a4e9-cbeb478770e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add metadata to attributes\n",
    "attrs = sampling_details\n",
    "attrs['start_date'] = start_date.strftime('%Y-%m-%d')\n",
    "end_date = sgridded['time'].data[-1]\n",
    "attrs['end_date'] = np.datetime_as_string(end_date,unit='D')\n",
    "attrs['ndays'] = ndays\n",
    "attrs.pop('DERIVED_VARIABLES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b7558b-4ef6-43d3-9037-6a9f54d2684e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------ subsampled data\n",
    "# this is slow and generates a huge file, so consider skipping\n",
    "if sampling_parameters['PLATFORM'] != 'mooring':\n",
    "    filename_out = filename_out_base + '_subsampled.nc'\n",
    "    print(f'saving to {filename_out}')\n",
    "    subsampled_data.attrs = attrs\n",
    "    netcdf_fill_value = nc4.default_fillvals['f4']\n",
    "    dv_encoding={'zlib':True,  # turns compression on\\\n",
    "                'complevel':9,     # 1 = fastest, lowest compression; 9=slowest, highest compression \\\n",
    "                'shuffle':True,    # shuffle filter can significantly improve compression ratios, and is on by default \\\n",
    "                'dtype':'float32',\\\n",
    "                '_FillValue':netcdf_fill_value}\n",
    "    # save to a new file\n",
    "    # subsampled_data.to_netcdf(filename_out,format='netcdf4',encoding=dv_encoding)\n",
    "    subsampled_data.to_netcdf(filename_out,format='netcdf4')\n",
    "    !ls -ltrh {filename_out}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8549dc91-7959-40cc-894f-5a957e92ef03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------ gridded:\n",
    "filename_out = filename_out_base + '_gridded.nc'\n",
    "print(f'saving to {filename_out}')\n",
    "sgridded.attrs = attrs\n",
    "netcdf_fill_value = nc4.default_fillvals['f4']\n",
    "dv_encoding={'zlib':True,  # turns compression on\\\n",
    "            'complevel':9,     # 1 = fastest, lowest compression; 9=slowest, highest compression \\\n",
    "            'shuffle':True,    # shuffle filter can significantly improve compression ratios, and is on by default \\\n",
    "            'dtype':'float32',\\\n",
    "            '_FillValue':netcdf_fill_value}\n",
    "# save to a new file\n",
    "# subsampled_data.to_netcdf(filename_out,format='netcdf4',encoding=dv_encoding)\n",
    "sgridded.to_netcdf(filename_out,format='netcdf4')\n",
    "!ls -ltrh {filename_out}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe744d39-6fd4-495c-9a50-53f720453879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------ gridded:\n",
    "filename_out = filename_out_base + '_gridded.nc'\n",
    "print(f'saving to {filename_out}')\n",
    "sgridded.attrs = attrs\n",
    "netcdf_fill_value = nc4.default_fillvals['f4']\n",
    "dv_encoding={'zlib':True,  # turns compression on\\\n",
    "            'complevel':9,     # 1 = fastest, lowest compression; 9=slowest, highest compression \\\n",
    "            'shuffle':True,    # shuffle filter can significantly improve compression ratios, and is on by default \\\n",
    "            'dtype':'float32',\\\n",
    "            '_FillValue':netcdf_fill_value}\n",
    "# save to a new file\n",
    "# subsampled_data.to_netcdf(filename_out,format='netcdf4',encoding=dv_encoding)\n",
    "sgridded.to_netcdf(filename_out,format='netcdf4')\n",
    "!ls -ltrh {filename_out}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f399a299-68a6-40c0-823e-a195c7f52fc3",
   "metadata": {},
   "source": [
    "### Visualize interpolated data in 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc7f711-a7a9-4410-abed-bf017d60df9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "ax = plt.axes(projection='3d')\n",
    "fig.subplots_adjust(left=0.25, bottom=0.25)\n",
    "\n",
    "ax.set_xlabel('longitude', fontsize=15, rotation=150)\n",
    "ax.set_ylabel('latitude',fontsize=15)\n",
    "ax.set_zlabel('depth', fontsize=15, rotation=60)\n",
    "\n",
    "p = ax.scatter3D(subsampled_data.lon.data, subsampled_data.lat.data, subsampled_data.dep.data, c=subsampled_data.Theta.data, s=1)\n",
    "fig.colorbar(p).set_label('Temperature ($^o$C)')\n",
    "ax.set_title('Temperature interpolated to the survey track')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
