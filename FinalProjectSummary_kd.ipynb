{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3e15606-e20b-45ed-872f-1dac2b874aa6",
   "metadata": {},
   "source": [
    "# OHW 2021 - Model Subsampling Project\n",
    "\n",
    "## OceanHackWeek21 project to subsample high-resolution model output as if by gliders, ships, or other *in situ* platforms\n",
    "\n",
    "The goal of this project is to create a Python package that takes an input trajectory (e.g., the path of an ocean glider or a ship-based underway CTD), subsamples output from a high-resolution ocean simulation along that trajectory, and returns a set of subsampled variables (e.g., standard physical variables temperature, salinity, velocity; derived physical quantities such as steric height; biogeochemical quantities if available). We envision this package having two potential uses: 1) designing in situ sampling strategies, and 2) interpreting in situ data in the context of a highly resolved oceanographic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b986eb-9b7a-4472-8040-ddbfc81e7290",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "\n",
    "# Third-party packages for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "# Third-party packages for data interpolation\n",
    "from scipy import interpolate\n",
    "\n",
    "# Third-party packages for data visualizations\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03f896a-a591-4627-9978-1587a7adfd7e",
   "metadata": {},
   "source": [
    "### Import model data\n",
    "\n",
    "We chose to subsample [LLC4320](https://data.nas.nasa.gov/viz/vizdata/llc4320/index.html), the 1/48-degree global MITgcm simulation produced by the ECCO project. Ten regional cut-outs of the simulation are available on the [PO.DAAC](https://podaac.jpl.nasa.gov/datasetlist?ids=Processing+Levels&values=4+-+Gridded+Model+Output&search=Pre-SWOT+llc4320&view=list&provider=): the 4x4 degree regiononal domains are small enough to enable fairly easy downloads and processing. The data from the model were retrieved using the first section of [`Pre-SWOT_Numerical_Simulation_Demo.ipynb`](https://github.com/podaac/tutorials/blob/master/notebooks/Pre-SWOT_Numerical_Simulation_Demo.ipynb) (everything before the \"Plot eight 2D fields\" heading) and saved as `LLC4320_pre-SWOT_ACC_SMST_20111221.nc`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d005bccf-90f9-4441-85a3-717118c10b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load model data\n",
    "ndays = 3 # number of days to load\n",
    "target_files = [f\"LLC4320_pre-SWOT_ACC_SMST_201112{day}.nc\" for day in range(21,21+3)] # list target files\n",
    "# Load all netCDF files\n",
    "ds = xr.open_mfdataset(target_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0218832c-5445-491d-84e4-8b6a4ccc3d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change coordinate of time to make life easier\n",
    "ds = ds.assign_coords(time=np.linspace(0,ds.time.size-1, num=ds.time.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aaa87ee-c2c3-4b7c-8469-65c43e7f8f67",
   "metadata": {},
   "source": [
    "LLC4320 data does not have lat, lon as coordinates; instead the coordinates are simply index numbers. This means that the lon-lat-depth passed for the trajectory will have to be converted to the corresponding index numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf2eb06-761a-4fda-bb26-8f4f938fb581",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert lon, lat and z to index i, j and k with f_x, f_y and f_z\n",
    "X = ds.XC.isel(time=0) # XC, YC and Z are the same at all times, so select a single tim\n",
    "Y = ds.YC.isel(time=0)\n",
    "i = ds.i\n",
    "j = ds.j\n",
    "z = ds.Z.isel(time=0)\n",
    "k = ds.k\n",
    "\n",
    "f_x = interpolate.interp1d(X[0,:].values, i)\n",
    "f_y = interpolate.interp1d(Y[:,0].values, j)\n",
    "f_z = interpolate.interp1d(z, k, bounds_error=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e7e749-fffa-48f4-bd31-d3dc3498814c",
   "metadata": {},
   "source": [
    "## Select sampling strategy\n",
    "\n",
    "Use the SAMPLING_STRATEGY variable to select whether you want to sample the model using a real glider track ('real_glider'), a simulated glider track ('sim_glider') or a simulated underway ctd ('sim_uctd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4564d0d-33a1-489d-b051-54e166a0914d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLING_STRATEGY = 'real_glider' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f97e72-0d1d-4588-8447-560b65b32c00",
   "metadata": {},
   "source": [
    "### If you would like to subsample the model using a real glider track, set `SAMPLING_STRATEGY = 'real_glider'` and the following cells will be run.\n",
    "\n",
    "Our example glider track original came from [this repo](https://github.com/earthcube2021/ec21_balwada_etal). It wasn't inside one of the regions covered by LLC4320. Here, we load the trajectory and transpose it such that it fits within the Southern Ocean region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a691b87-fc2b-4894-a2d2-5dcf02ff2fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAMPLING_STRATEGY == 'real_glider':\n",
    "    ## Load and transpose glider data\n",
    "\n",
    "    # Load data\n",
    "    ds_CTD_659 = xr.load_dataset('CTD_659.nc')\n",
    "\n",
    "    # Print glider boundaries\n",
    "    s = 'Original glider boundaries:\\nNorth: {n}\\nSouth: {s}\\nEast: {e}\\nWest: {w}\\n'.format(\n",
    "        n=ds_CTD_659.latitude.data.max(),\n",
    "        s=ds_CTD_659.latitude.data.min(),\n",
    "        e=ds_CTD_659.longitude.data.max(),\n",
    "        w=ds_CTD_659.longitude.data.min()\n",
    "    )\n",
    "    print(s)\n",
    "\n",
    "    # Get boundaries of model region\n",
    "    model_boundary_n = ds.YC.max()\n",
    "    model_boundary_s = ds.YC.min()\n",
    "    model_boundary_w = ds.XC.min()\n",
    "    model_boundary_e = ds.XC.max()\n",
    "\n",
    "    # Print model boundaries\n",
    "    s = 'Model boundaries:\\nNorth: {n}\\nSouth: {s}\\nEast: {e}\\nWest: {w}\\n'.format(\n",
    "        n=model_boundary_n.data,\n",
    "        s=model_boundary_s.data,\n",
    "        e=model_boundary_e.data,\n",
    "        w=model_boundary_w.data\n",
    "    )\n",
    "    print(s)\n",
    "\n",
    "    # Transpose latitude\n",
    "    shifted_lat = (ds_CTD_659.latitude - ds_CTD_659.latitude.min()\n",
    "                  )/(ds_CTD_659.latitude.max() - ds_CTD_659.latitude.min()\n",
    "                    )*(model_boundary_n-model_boundary_s)+ model_boundary_s\n",
    "\n",
    "\n",
    "    # Transpose longitude\n",
    "    shifted_lon = (ds_CTD_659.longitude - ds_CTD_659.longitude.min()\n",
    "                  )/(ds_CTD_659.longitude.max() - ds_CTD_659.longitude.min()\n",
    "                    )*(model_boundary_e-model_boundary_w)+ model_boundary_w\n",
    "\n",
    "    # Print transposed glider boundaries\n",
    "    s = 'Transposed glider boundaries:\\nNorth: {n}\\nSouth: {s}\\nEast: {e}\\nWest: {w}\\n'.format(\n",
    "        n=shifted_lat.max().data,\n",
    "        s=shifted_lat.min().data,\n",
    "        e=shifted_lon.max().data,\n",
    "        w=shifted_lon.min().data\n",
    "    )\n",
    "    print(s)\n",
    "    \n",
    "    \n",
    "    ## Assemble trajectory dataset\n",
    "\n",
    "    # Remove NaN values from pressure (depth) data\n",
    "    depth = -ds_CTD_659.pressure.where(~np.isnan(ds_CTD_659.pressure), drop=True)\n",
    "    n = len(depth)\n",
    "\n",
    "    ## Assemble dataset\n",
    "    # real (lat/lon) coordinates\n",
    "    survey_track = xr.Dataset(\n",
    "        dict(\n",
    "            lon = xr.DataArray(shifted_lon.where(~np.isnan(ds_CTD_659.pressure), drop=True),dims='points'),\n",
    "            lat = xr.DataArray(shifted_lat.where(~np.isnan(ds_CTD_659.pressure), drop=True),dims='points'),\n",
    "            dep = xr.DataArray(depth,dims='points'),\n",
    "            time = xr.DataArray(np.linspace(ds.time[0], ds.time[-1]/24, num=n),dims='points') # convert time from # of hourly steps to days \n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # transform to i,j,k coordinates:\n",
    "    survey_track= xr.Dataset(\n",
    "        dict(\n",
    "            i = xr.DataArray(f_x(survey_track.lon), dims='points'),\n",
    "            j = xr.DataArray(f_y(survey_track.lat), dims='points'),\n",
    "            k = xr.DataArray(f_z(survey_track.dep), dims='points'),\n",
    "            time = xr.DataArray(survey_track.time,dims='points')\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fcd38d-86d8-4d57-bc0d-02af4b8da5d8",
   "metadata": {},
   "source": [
    "### If you would like to subsample the model using a simulated glider or ship-based uCTD track, set `SAMPLING_STRATEGY = 'sim_glider'` or `'sim_uctd'` and the following cells will be run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9cdb0e-1086-4ebf-b458-fdbe9d8d36f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAMPLING_STRATEGY == 'sim_glider' or SAMPLING_STRATEGY == 'sim_uctd':\n",
    "    # code originally from make_trajectory.ipnyb\n",
    "    # --------- define sampling: change the values in this section -------\n",
    "    PATTERN = 'lawnmower' # back-forth or lawnmower ... could add others\n",
    "    survey_time_total = ndays * 86400 # if non-zero, limits the survey to a total time\n",
    "\n",
    "\n",
    "    # typical speeds and depth ranges based on platform \n",
    "    if SAMPLING_TYPE == 'sim_uctd':\n",
    "        # typical values for uctd sampling:\n",
    "        zrange = [-5, -500] # depth range of profiles (down is negative)\n",
    "        hspeed = 5 # platform horizontal speed in m/s\n",
    "        vspeed = 1 # platform vertical (profile) speed in m/s (NOTE: may want different up/down speeds)\n",
    "\n",
    "    elif SAMPLING_TYPE == 'sim_glider':\n",
    "        # typical values for glider sampling:\n",
    "        zrange = [-1, -1000] # depth range of profiles (down is negative)\n",
    "        hspeed = 0.25 # platform horizontal speed in m/s\n",
    "        vspeed = 0.25 # platform vertical (profile) speed in m/s  (NOTE: is this typical?)\n",
    "\n",
    "    # define x & y waypoints and z range\n",
    "    # - these are for the ACC_SMST region specifically ... could make generic based on the lat/lon of the domain\n",
    "    # xwaypoints & ywaypoints must have the same size\n",
    "    if PATTERN == 'lawnmower':\n",
    "        # \"mow the lawn\" pattern - define all waypoints\n",
    "        xwaypoints = [151, 151, 151.5, 151.5, 152, 152, 152.5, 152.5]\n",
    "        ywaypoints = [-56, -55,   -55,   -56, -56, -55, -55, -56] \n",
    "    elif PATTERN == 'back-forth':\n",
    "        # repeated back & forth transects - define the end-points\n",
    "        xwaypoints = [151, 152]\n",
    "        ywaypoints = [-56, -55]\n",
    "        # repeat waypoints based on # of transects: \n",
    "        dkm_per_transect = great_circle(xwaypoints[0], ywaypoints[0], xwaypoints[1], ywaypoints[1]) # distance of one transect in km\n",
    "        t_per_transect = dkm_per_transect * 1000 / hspeed # time per transect, seconds\n",
    "        num_transects = np.round(sample_time_total / t_per_transect)\n",
    "        for n in np.arange(num_transects):\n",
    "            xwaypoints = np.append(xwaypoints, xwaypoints[-2])\n",
    "            ywaypoints = np.append(ywaypoints, ywaypoints[-2])\n",
    "\n",
    "    # time resolution of sampling (dt):\n",
    "    # use the time between vertical measurements\n",
    "    # for now, use a constant  vertical resolution (can change this later)\n",
    "    zresolution = 10 # meters\n",
    "    zprofile = np.arange(zrange[0],zrange[1],-zresolution) # depths for one profile\n",
    "    ztwoway = np.append(zprofile,zprofile[-1:0:-1])\n",
    "\n",
    "    dt = zresolution / vspeed # sampling resolution in seconds\n",
    "    # for each timestep dt \n",
    "    deltah = hspeed*dt # horizontal distance traveled per sample\n",
    "    deltav = vspeed*dt # vertical distance traveled per sample\n",
    "\n",
    "\n",
    "    # determine the sampling locations in 2-d space\n",
    "    # - initialize sample locations xs, ys, zs, ts\n",
    "    xs = []\n",
    "    ys = []\n",
    "    zs = []\n",
    "    ts = []\n",
    "    dkm_total = 0 \n",
    "    # great circle distance (from Jake Steinberg) (move this to the top?)\n",
    "    from math import radians, degrees, sin, cos, asin, acos, sqrt\n",
    "    def great_circle(lon1, lat1, lon2, lat2):\n",
    "        lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "        return 6371 * (acos(sin(lat1) * sin(lat2) + cos(lat1) * cos(lat2) * cos(lon1 - lon2)))\n",
    "\n",
    "    for w in np.arange(len(xwaypoints)-1):\n",
    "        # interpolate between this and the following waypoint:\n",
    "        dkm = great_circle(xwaypoints[w], ywaypoints[w], xwaypoints[w+1], ywaypoints[w+1])\n",
    "        # number of time steps (vertical measurements) between this and the next waypoint\n",
    "        nstep = int(dkm*1000 / deltah) \n",
    "        yi = np.linspace(ywaypoints[w], ywaypoints[w+1], nstep)\n",
    "        xi = np.linspace(xwaypoints[w], xwaypoints[w+1], nstep)\n",
    "        xi = xi[0:-1] # remove last point, which is the next waypoint\n",
    "        xs = np.append(xs, xi) # append\n",
    "        yi = yi[0:-1] # remove last point, which is the next waypoint\n",
    "        ys = np.append(ys, yi) # append\n",
    "        dkm_total = dkm_total + dkm\n",
    "        t_total = dkm_total * 1000 / hspeed\n",
    "        # cut off the survey after survey_time_total, if specified\n",
    "        if survey_time_total > 0 and t_total > survey_time_total:\n",
    "            break\n",
    "\n",
    "    # depths: repeat (tile) the two-way sampling depths (NOTE: for UCTD sampling, often only use down-cast data)\n",
    "    # how many profiles do we make during the survey?\n",
    "    n_profiles = np.ceil(xs.size / ztwoway.size)\n",
    "    zs = np.tile(ztwoway, int(n_profiles))\n",
    "    zs = zs[0:xs.size]\n",
    "    # sample times: (units are in seconds since zero => convert to days, to agree with ds.time)\n",
    "    ts = dt * np.arange(xs.size) / 86400 \n",
    "    \n",
    "    ## Assemble dataset:\n",
    "    # real (lat/lon) coordinates\n",
    "    survey_track = xr.Dataset(\n",
    "        dict(\n",
    "            lon = xr.DataArray(xs,dims='points'),\n",
    "            lat = xr.DataArray(ys,dims='points'),\n",
    "            dep = xr.DataArray(zs,dims='points'),\n",
    "            time = xr.DataArray(ts,dims='points')\n",
    "        )\n",
    "    )\n",
    "    # transform to i,j,k coordinates:\n",
    "    survey_track= xr.Dataset(\n",
    "    dict(\n",
    "        i = xr.DataArray(f_x(survey_track.lon), dims='points'),\n",
    "        j = xr.DataArray(f_y(survey_track.lat), dims='points'),\n",
    "        k = xr.DataArray(f_z(survey_track.dep), dims='points'),\n",
    "        time = xr.DataArray(survey_track.time,dims='points'),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f78c0ba-ce75-4d67-9e9c-2949ca197c5c",
   "metadata": {},
   "source": [
    "### Perform the interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfc9091-3625-4e18-a04b-d60d44ae26f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataset to contain the interpolated data\n",
    "subsampled_data = xr.Dataset() # NOTE: add more metadata to this dataset?\n",
    "subsampled_data['Theta']=ds.Theta.interp(survey_track) # NOTE: is there a smarter way to do this using variable names and a loop?\n",
    "subsampled_data['Salt']=ds.Theta.interp(survey_track) \n",
    "subsampled_data['lon']=survey_track.lon\n",
    "subsampled_data['lat']=survey_track.lat\n",
    "subsampled_data['dep']=survey_track.dep\n",
    "subsampled_data['time']=survey_track.time\n",
    "subsampled_data\n",
    "# test plot\n",
    "subsampled_data.Theta.plot(x='time') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e0c47b-6ab7-4eaf-97e2-6c00caa75834",
   "metadata": {},
   "source": [
    "### Interpolate variables that are not on the i-j grid, but shifted. \n",
    "\n",
    "Roughly based on: https://xgcm.readthedocs.io/en/latest/xgcm-examples/02_mitgcm.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0638c13e-df93-42db-be32-7822708f2a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgcm import Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4840c2ca-e43b-4623-b17c-747e972d5c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = Grid(ds, coords={'X':{'center': 'i', 'left': 'i_g'}, \n",
    "                 'Y':{'center': 'j', 'left': 'j_g'},\n",
    "                 'Z':{'center': 'k'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e773ef3-a620-4baf-b2b2-163f06819d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolate U and V from i_g, j_g to i, j \n",
    "U_c = grid.interp(ds.U, 'X', boundary='extend')\n",
    "V_c = grid.interp(ds.V, 'Y', boundary='extend')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efda5959-9d1c-44e5-962d-9043afe804de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute vorticity and interpolate to i,j\n",
    "Vort = (grid.diff(ds.V*ds.DXG, 'X') - grid.diff(ds.U*ds.DYG, 'Y'))/ds.RAZ\n",
    "Vort = grid.interp(grid.interp(Vort, 'X', boundary='extend'), 'Y', boundary='extend')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007e22c2-6acd-4f3a-938e-2af7d877fd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Vort.isel(time=0, k=0).plot\n",
    "# there is a little boundary problem in the calculation, but can be dealt with if wanted. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a525536-7b06-4584-90f6-ecd0a1a36e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolate and add to subsampled_data\n",
    "subsampled_data['U'] = U_c.interp(survey_track)\n",
    "subsampled_data['V'] = V_c.interp(survey_track)\n",
    "subsampled_data['Vort'] = Vort.interp(survey_track)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90630fe-ba8c-42cf-8731-6eae7d039996",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "subi=np.arange(0,subsampled_data.lon.size,10) # subsample for faster plotting - looks kind of weird though\n",
    "plt.scatter(survey_track.time[subi], survey_track.dep[subi], c=subsampled_data['U'].isel(points=subi), vmin=-0.5, vmax=0.5, cmap=\"RdBu_r\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359d7390-317c-453d-8d9c-0755f437de03",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.scatter(survey_track.time[subi], survey_track.dep[subi], c=subsampled_data['Vort'].isel(points=subi)/1e-4, vmin=-0.5, vmax=0.5, cmap=\"RdBu_r\")\n",
    "plt.colorbar()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
